You’re not crazy — “vibe code” is a specific monday.com thing now, not just a TikTok vibe.

What monday.com “Vibe” and “AI blocks” actually are

monday vibe = an AI-powered app builder inside monday that turns prompts into “fully custom… business apps” that run on their platform.  ￼
Under the hood, those apps live in monday’s ecosystem and talk to monday data through their Apps Framework + GraphQL Platform API.  ￼

Their AI layer is packaged as AI blocks:
	•	AI blocks are “the central AI features,” reusable across AI Columns, Automations, and the workflow builder.  ￼
	•	On the dev side, monday’s SDK is designed for building UI extensions (views/widgets) and automations/integrations that often run via your external services.  ￼
	•	They’re also nudging devs from older “actions/recipes” toward their newer workflows infrastructure.  ￼

So: Vibe = AI app generator + monday’s data/workflow runtime.
AI blocks = modular LLM-powered transformations you can drop into workflows/columns.

⸻

The open-source-ish replacement (self-hosted) that matches monday vibe best

You won’t find a single open-source clone that perfectly recreates monday vibe end-to-end (because it’s tightly coupled to monday’s platform). But you can recreate the capabilities with a clean stack:

1) “Vibe app builder” (UI + permissions + CRUD)

Pick one:
	•	NocoBase (open-source low-code business apps; often used for “internal systems” style builds)  ￼
	•	Budibase (open-source low-code; self-host via Docker/K8s)  ￼
	•	Appsmith (open-source low-code; explicitly supports self-hosting + “AI-powered apps and agents”)  ￼

These give you the “boards/CRM/admin panels” surface area that monday generates for you.

2) “AI blocks” (drop-in AI steps inside workflows)

Use an agent/workflow orchestrator that you control:
	•	LangGraph (open-source framework for building stateful, multi-step agents/workflows)  ￼

This is where you implement your equivalents of monday’s AI blocks:
	•	summarize → classify → extract fields → draft email → generate tasks → validate → human approval → commit changes

3) “Automations / integrations” (the glue)
	•	n8n (self-hostable workflow automation; they position it heavily for AI + multi-step agents)  ￼

(Real talk: keep n8n off the public internet and patched; it’s had serious security issues when exposed/misconfigured.  ￼)

4) “Private server models” (your LLM runtime)

Two common patterns:

Production-grade serving (recommended):
	•	vLLM OpenAI-compatible server (host models behind an OpenAI-style API so your app can swap models easily)  ￼

Developer-friendly (fast to start):
	•	Ollama (very easy local model runner; great for dev)  ￼
Security note: lots of people accidentally expose Ollama instances; don’t.  ￼

5) Which open(-weights) models to use (practical picks)

You’ll likely want two models: one “reasoning/general” and one “coding/tool-use”.
	•	Strong “general assistant” families people commonly self-host: Llama, Qwen, Mixtral, DeepSeek (weights availability depends on the exact model/license).  ￼
	•	If you want something explicitly documented for self-host via vLLM with an OpenAI cookbook: OpenAI’s gpt-oss-20b / gpt-oss-120b (serving guide)  ￼

⸻

A concrete “Vericase replaces monday vibe” architecture

Frontend / app builder: Appsmith or Budibase or NocoBase
Core app: your Vericase API (auth, matters, clients, docs, audit logs)
Workflow engine: n8n (event routing, integrations)
AI orchestration: LangGraph (“AI blocks” as code: classify/extract/draft/verify/human-approve)
Model serving: vLLM (OpenAI-compatible endpoint), optionally Ollama for dev
Storage: Postgres + object storage (S3/MinIO) + vector DB (pgvector is usually enough)

That reproduces monday’s “prompt → app + workflows + AI blocks” vibe, except you own the runtime and can keep it inside your private server.

⸻

My blunt recommendation (so you don’t build a Rube Goldberg machine)

If your goal is closest to monday vibe while staying self-hosted:
	•	NocoBase (or Budibase) for the “generated app” feel  ￼
	•	LangGraph for your “AI blocks” layer  ￼
	•	vLLM for serving models behind a clean API  ￼
	•	Add n8n only if you truly need lots of third-party connectors—otherwise keep workflows inside your backend for security/simplicity.  ￼

This combo gets you 80% of monday’s magic with 0% of monday’s “your data lives in someone else’s cloud” energy.

If you keep pushing forward-thinking: build your “AI blocks” as a versioned library (inputs/outputs, cost, latency, eval tests). That’s how you avoid the classic fate of AI apps: “works in the demo, haunts you in production.”